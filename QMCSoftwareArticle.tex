%
% sample root file for your "contribution" to a contributed volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[graybox,footinfo]{svmult}

\smartqed
\usepackage{mathptmx}       % selects Times Roman as basic font
\usepackage{helvet}         % selects Helvetica as sans-serif font
\usepackage{courier}        % selects Courier as typewriter font
\usepackage{type1cm}        % activate if the above 3 fonts are
% not available on your system
\usepackage{graphicx}       % standard LaTeX graphics tool
% when including figure files

\usepackage{array,colortbl}
\usepackage{amsmath,amsfonts,amssymb,bm} % no amsthm, Springer defines Theorem, Lemma, etc themselves
%\usepackage[mathx]{mathabx}
\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{
	<5> <6> <7> <8> <9> <10>
	<10.95> <12> <14.4> <17.28> <20.74> <24.88>
	mathx10
}{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}
\DeclareMathAccent{\widecheck}      {0}{mathx}{"71}



% Note that Springer defines the following already:
%
% \D upright d for differential d
% \I upright i for imaginary unit
% \E upright e for exponential function
% \tens depicts tensors as sans serif upright
% \vec depicts vectors as boldface characters instead of the arrow accent
%
% Additionally we throw in the following common used macro's:
\input{macros}

% Macros below are now included in macros.tex from MCQMC 2016 web site
% This spot formerly included macros that are now in macros.tex

% indicator boldface 1:
\DeclareSymbolFont{bbold}{U}{bbold}{m}{n}
\DeclareSymbolFontAlphabet{\mathbbold}{bbold}
%\newcommand{\ind}{\mathbbold{1}}


\usepackage{microtype} % good font tricks

\usepackage[colorlinks=true,linkcolor=black,citecolor=black,urlcolor=black]{hyperref}
\urlstyle{same}
\usepackage{bookmark}
\pdfstringdefDisableCommands{\def\and{, }}
\makeatletter % to avoid hyperref warnings:
\providecommand*{\toclevel@author}{999}
\providecommand*{\toclevel@title}{0}
\makeatother



\usepackage{bbm,mathtools,array,longtable,booktabs,graphicx,color,enumitem}
%\input FJHDef.tex


\newcommand{\QMCPYnorm}[2][{}]{\ensuremath{\left \lVert #2 \right \rVert}_{#1}}
\newcommand{\QMCPYnormnorm}[2][{}]{\ensuremath{\lVert #2 \rVert}_{#1}}
\newcommand{\QMCPYbignorm}[2][{}]{\ensuremath{\bigl \lVert #2 \bigr \rVert}_{#1}}
\newcommand{\QMCPYBignorm}[2][{}]{\ensuremath{\Bigl \lVert #2 \Bigr \rVert}_{#1}}
\newcommand{\QMCPYabs}[1]{\ensuremath{{\left \lvert #1 \right \rvert}}}
\newcommand{\QMCPYbigabs}[1]{\ensuremath{{\bigl \lvert #1 \bigr \rvert}}}


\providecommand{\HickernellFJ}{Hickernell}

\definecolor{orange}{rgb}{1.0,0.3,0.0}
\definecolor{violet}{rgb}{0.75,0,1}
\newcommand{\frednote}[1]{  {\textcolor{red}  {\mbox{**Fred:} #1}}}
\newcommand{\yuhannote}[1]{ {\textcolor{violet}  {\mbox{**Yuhan:} #1}}}
\newcommand{\tonynote}[1]{ {\textcolor{orange}  {\mbox{**Tony:} #1}}}

%\journal{Journal of Complexity}

\allowdisplaybreaks[4]


\newcommand{\AGSComment}[1]{{\color{cyan} Aleksei: #1}}

\newcommand{\hmu}{\widehat{\mu}}
\newcommand{\IID}{\textup{IID}}
\newcommand{\LD}{\textup{LD}}
\newcommand{\unif}{\textup{unif}}
\newcommand{\IIDsim}{\overset{\IID}{\sim}}
\newcommand{\LDsim}{\overset{\LD}{\sim}}

\begin{document}

\title*{Quasi-Monte Carlo Software}
\authorrunning{S.-C.\ T.\ Choi, F. J. Hickernell, R. Jagadeeswaran, M. J. McCourt, and A. G. Sorokin}
\author{Sou-Cheng Terrya Choi \and Fred J. Hickernell \and R. Jagadeeswaran \and Michael J. McCourt \and Aleksei Sorokin}
\institute{Sou-Cheng Terrya Choi \at Department of Applied Mathematics, Illinois Institute of Technology,\\ RE 220, 10 W.\ 32$^{\text{nd}}$ St., Chicago, IL 60616 \email{yding2@hawk.iit.edu}
\and
Fred J. Hickernell \at Center for Interdisciplinary Scientific Computation and \\
Department of Applied Mathematics, Illinois Institute of Technology \\ RE 220, 10 W.\ 32$^{\text{nd}}$ St., Chicago, IL 60616 \email{hickernell@iit.edu}
\and
R. Jagadeeswaran \at
\and
Michael J. McCourt \at ???
\and 
Aleksei G. Sorokin \at
Department of Applied Mathematics, Illinois Institute of Technology,\\ RE 220, 10 W.\ 32$^{\text{nd}}$ St., Chicago, IL 60616 \email{asorokin@hawk.iit.edu}}

\maketitle

\abstract{This is the article based on my MCQMC 2020 Tutorial}



\section{Introduction}
Quasi-Monte Carlo (QMC) methods promise great efficiency gains over independent and identically distributed (IID) Monte Carlo (MC) methods.  In some cases QMC may achieve one hundredth of the error as IID MC in the same amount of time. Often, these efficiency gains are obtained simply by  replacing IID sampling by the low discrepancy (LD) sampling that is at the heart of QMC. 

If you are a practitioner, you would like to test whether QMC would speed your computation.  You would like easy access to the best QMC algorithms available.  If you are a theoretician or algorithm developer, you would like try out your best ideas on a variety of use cases to demonstrate their practical value.  

This tutorial points to some of the best QMC software available.  Moreover, we describe QMCPy \cite{QMCPy2020a}, which is designed to become a community owned Python library that combines the best QMC algorithms under a common user interface.  A demonstration of how QMCPy works is given in a Google colaboratory notebook \cite{QMCPyTutColab2020}.

The model problem for QMC is to approximate an integral,
\begin{equation} \label{eq:integral}
	\mu := \int_\calT g(\bst) \, \lambda(\bst) \, \D \bst,
\end{equation}
where $g$ is the integrand, and $\lambda$ is a non-negative weight.  We use $\mu$ to denote the value of this integral because we perform a transformation to interpret it as the population mean of a random variable, 
\begin{equation} \label{eq:fintegral}
	\mu = \bbE[f(\bsX)] = \int_\calX f(\bsx) \, \varrho(\bsx) \, \D \bsx =  \int_\calX f(\bsx) \,  \D F(\bsx) ,
\end{equation}
where $\varrho$ is a probability density with corresponding probability distribution $F$. 
A good choice of $f$ can make computation more efficient.

QMC approximates this population mean by a sample mean,
\begin{equation} \label{eq:samplemean}
	\hmu := \frac 1n \sum_{i=0}^{n-1} f(\bsX_i), \qquad \bsX_0, \bsX_1, \ldots \sim F.
\end{equation}
The choice of this sequence, and the choice of $n$ to satisfy  the prescribed error tolerance are important decisions.  QMC software helps the user make those decisions.

Here, the notation ``$\sim$'' means that the sequence mimics the specified, target distribution, but not necessarily in a probabilistic way.  We  use this notation in two forms:  $\IIDsim$ and $\LDsim$.

IID points are random. The position of each point is not influenced by the other, so clusters and gaps occur.  A subset of IID points chosen randomly is also IID.  When we say that $\bsX_0, \bsX_1, \ldots \IIDsim F$, we mean that for any positive integer $n$, the  multivariate probability distribution of $\bsX_0, \ldots, \bsX_{n-1}$ is the product of the marginals, specifically,
\begin{equation*}
	F_{n}(\bsx_0, \ldots, \bsx_{n-1}) = F(\bsx_0) \cdots  F(\bsx_{n-1}).
\end{equation*}
When IID points are used to approximate $\mu$ by the sample mean, the error is $\calO(n^{-1/2})$.  Figure \ref{fig:comparePts} displays IID uniform points, $\bsX^{\IID}_0, \bsX^{\IID}_1, \ldots \IIDsim \calU[0,1]^2$, where the target distribution is $F(\bsx) = x_1 x_2$


\begin{figure}
	\includegraphics[height=5cm]{ProgramsImages/IIDPoints.eps} \qquad
	\includegraphics[height=5cm]{ProgramsImages/SSobolPoints.eps}
	\caption{IID points contrasted with LD points.  The LD points cover the square more evenly.} \label{fig:comparePts}
\end{figure}

LD points may be deterministic or random, but each point is carefully coordinated with the other so that they fill the square well.  When we say that $\bsX_0, \bsX_1, \ldots \LDsim F$, we mean that for any positive integer $n$,  the empirical distribution of $\bsX_0, \ldots, \bsX_{n-1}$, denoted $F_{\{\bsX_i\}_{i=0}^{n-1}}$,  approximate the target distribution, $F$, well (relative to $n$).  (The empirical distribution of a set assigns equal probability to each point.)  The measure of the difference between the empirical distribution of a set of points and the target distribution is called a \emph{discrepancy} and is denoted $D(\{\bsX_i\}_{i=0}^{n-1}, F)$.  This is the origin of the term low discrepancy points.  LD points by definition have a smaller discrepancy than IID points.  Figure \ref{fig:comparePts} contrasts IID uniform points with LD points, $\bsX^{\LD}_0, \bsX^{\LD}_1 \ldots \LDsim \calU[0,1]^2$, in this case linearly scrambled Sobol' points. For most LD sequences, the target distribution is $\calU[0,1]^d$.

The error of the sample mean in approximating the integral can be bounded according to the Koksma-Hlawka and its extensions as the product of the discrepancy of the sampling sequence and the variation of the integrand, denoted $V(\cdot)$:
\begin{equation}
	\QMCPYabs{\mu - \hmu} = \QMCPYabs{\int_{\calX} f(\bsx) \, \D (F - F_{\{\bsX_i\}_{i=0}^{n-1}}) (\bsx)} \le D(\{\bsX_i\}_{i=0}^{n-1}, F) V(f),
\end{equation} 
The variation is a (semi-) norm of the integrand in a suitable Banach space.  The discrepancy corresponds to the norm of the error functional for that Banach space.  For typical Banach spaces, the discrepancy of LD points is $\calO(n^{-1+\epsilon})$, which is a higher convergence order than for IID points.  For details, the reader is referred to the references.  For our purposes, the we hope  that the reader sees here in Figure \ref{fig:comparePts} that the LD points cover the integration domain more evenly than IID points and that in the examples below the reader will see the demonstrably smaller cubature errors.

In the sections that follow we first overview available QMC software.  We next describe an architecture for good QMC software, i.e., what are the key components and how should they interact.  We then describe how we have implemented this architecture in QMCPy.  Finally, we summarize further directions that we hope QMCPy and related software projects will take.  Those interested in following the development of QMCPy or even contributing to its growth are urged to visit the GitHub repository at \href{https://qmcsoftware.github.io/QMCSoftware/}{\nolinkurl{https://qmcsoftware.github.io/QMCSoftware/}}.

\section{Available Software for QMC} \label{sec:available} 
QMC software spans three categories:  LD sequence generators, algorithms, and applications.  We review the better known software collections, recognizing that some software overlaps multiple categories.
Software focusing on generating high quality LD sequences  or their generators includes
\begin{description}[format=\textup,format=\textbf]
	\item[BRODA] Sobol' sequences in C, MATLAB, and Excel \cite{BRODA20a},
	\item[Burkhardt] various QMC software in C++, Fortran, MATLAB, \& Python \cite{Bur20a},
	\item[LatNet Builder] Generating vectors/matrices for lattices and digital nets \cite{LatNet},
	\item[MATLAB] Sobol' and Halton sequences, commercial \cite{MAT9.9},
	\item[MPS] Magic Point Shop, lattices and Sobol' sequences \cite{Nuy17a},
	\item[Owen] Randomized Halton sequences in R \cite{Owe20a},
	\item[PyTorch] Scrambled Sobol' sequences \cite{PyTorch},
	\item[QMC.jl] LD Sequences in Julia \cite{Rob20a}, and
	\item [qrng]  Sobol' and Halton sequences in R \cite{QRNG2020}.
\end{description}
Software focusing on QMC algorithms and applications includes
\begin{description}[format=\textup,format=\textbf]
	\item[GAIL] Automatic (Q)MC stopping criteria in MATLAB \cite{ChoEtal20a},
	\item[ML(Q)MC] Multi-Level (Quasi-)Monte Carlo routines in C++, MATLAB, Python, and R \cite{GilesSoft},
	\item[OpenTURNS] Open source initiative for the Treatment of Uncertainties, Risks 'N Statistics in Python \cite{OpenTURNS},
	\item[QMC4PDE] QMC for elliptic PDEs with random diffusion coefficients \cite{KuoNuy16a},
	\item[SSJ] Stochastic Simulation in Java \cite{SSJ}, and
	\item[UQLab] Framework for Uncertainty Quantification in MATLAB \cite{UQLab2014}.
\end{description}

The sections that follow describe QMCPy \cite{QMCPy2020a}, which is our attempt to combine the best of the above software under a common user interface and written in Python 3.  The choice of language was determined by the desire to make QMC software accessible to a broad audience, especially the tech industry.


\section{Components of QMC Software}
QMC cubature can be summarized as follows.  We want to approximate $\mu$ well by $\hmu$, where \eqref{eq:integral}, \eqref{eq:fintegral}, and \eqref{eq:samplemean} combine to give
\begin{multline} \label{eq:cubSummary}
	\mu : = \int_\calT g(\bst) \, \lambda(\bst) \, \D \bst  = \bbE[f(\bsX)] = \int_\calX f(\bsx) \, \varrho(\bsx) \, \D \bsx \approx \frac 1n \sum_{i=0}^{n-1} f(\bsX_i) =: \hmu, \\
	 \bsX_0, \bsX_1, \ldots \sim F.
\end{multline}
This required four components, which we implement in QMCPy as classes:

\begin{description}[format=\textup,format=\textbf]
	
	\item[Discrete Distribution] that produces $\bsX_0, \bsX_1, \dots$ mimicking the distribution $F$, which typically is $\calU[0,1]^d$;
	
	\item[True Measure] $\bst \mapsto \lambda (\bst) \D \bst$ that defines the original integral, e.g., Gaussian or Lebesgue;
	
	\item[Integrand] $g$ that  defines the original integral, plus the transformed version, $f$, to fit the discrete distribution; and
	
	\item[Stopping Criterion] that determines how large $n$ should be to ensure that $\QMCPYabs{\mu - \hmu_n} \le \varepsilon$.
\end{description}

The software libraries referenced in Section \ref{sec:available} provide one or more of these components.  QMCPy combines multiple examples of them all.


\section{Discrete Distributions}

LD sequences typically mimic $\calU[0,1]^d$, which we assume here.  Good sequences for other distributions are obtained by transformations in the next section.  

QMCPy implements \emph{extensible} LD sequences, i.e., those that allow practitioners to obtain and use additional $f(\bsX_i)$ without discarding the existing $f(\bsX_i)$.  Halton sequences do not have preferred sample sizes $n$, but integration lattices and digital sequences do.  These latter two also have an elegant group structure, which we summarize here.  

For simplicity we restrict ourselves to the case where the first $2^m$ points of these LD sequences form a group under the addition operator $\oplus$.

\[
	\renewcommand{\arraystretch}{1.3}
\begin{array}{c@{\qquad}c}
	\toprule
	\multicolumn{2}{c}{\text{Define \ldots}} \\
	\multicolumn{2}{c}{\bsZ_0 = \bszero, \qquad \bsZ_1, \bsZ_2, \bsZ_4, \ldots \in [0,1)^d \text{chosen well} } \\
	\multicolumn{2}{c}{
		\bsZ_{i + 2^m} := \bsZ_i \oplus \bsZ_{2^m} 
		 \qquad
    	\forall  i \in \{1, \ldots, 2^{m} -1\}, \ m \in \bbN_0 }\\
    	\multicolumn{2}{c}{\bsX_i := \bsZ_i \oplus \bsDelta, \qquad \bsDelta \IIDsim [0,1)^d} \\  \hline
	\text{Rank-1 Integration Lattices} & \text{Digital Nets} \\
		\bst \oplus \bsx : = \bst + \bsx \bmod \bsone & \bst \oplus \bsx := \text{binary digitwise addition} \\ 
		 \text{require } \begin{array}{l} \bsZ_1 = (1/2, \ldots, 1/2) \\
		 	\bsZ_{2^{m}} \oplus \bsZ_{2^{m}} = \bsZ_{2^{m-1}} \quad \forall m \in \bbN \end{array}
		\\
\toprule
\multicolumn{2}{c}{\text{Then it follows that \ldots}} \\
	\multicolumn{2}{c}{\begin{array}{r}
			\calP_m := \{\bsZ_0, \ldots, \bsZ_{2^m-1}\}, \quad
			\bsZ_i \oplus \bsZ_j \in \calP_m \\
			\calP_{\bsDelta,m} := \{\bsX_0, \ldots, \bsX_{2^m-1}\}, \quad
			\bsX_i \oplus \bsX_j \ominus \bsX_k \in \calP_{\bsDelta,m}
	\end{array} \quad \begin{array}{l}\forall  i,j,k \in \{0, \ldots, 2^{m} -1\} \\ \forall m \in \bbN_0\end{array}}
\end{array}
\]

We focus on integration lattice.  here on the case where a single LD sequence works well for sample sizes $n=1, 2, 4, 8, \ldots$.  This allows the user to obtain additional function data without discarding the existing function data.  


\section{True Measure}

\section{Integrands}

\section{Stopping Criteria}

\section{Under the Hood}



\section{Further Work} \label{sec:further}


\begin{acknowledgement}
The authors would like to thank the organizers for a wonderful MCQMC 2020. 
We also thank the referees for their many helpful suggestions.  This work is supported in part by National Science Foundation grants DMS-1522687 and SigOpt.


\end{acknowledgement}

%\section*{References}
%\nocite{*}
\bibliographystyle{spmpsci.bst}
\bibliography{FJH23,FJHown23}


\end{document}

